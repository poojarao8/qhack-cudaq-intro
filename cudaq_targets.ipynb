{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling applications in CUDA Quantum\n",
    "Main reference: https://nvidia.github.io/cuda-quantum/latest/examples/python/tutorials/multi_gpu_workflows.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets\n",
    "\n",
    "    - A combination of quantum circuit simulators and hardware.\n",
    "    - Allows you to switch between QPUs, CPUs and GPUs.\n",
    "    - The default target provides a state vector simulator based on the CPU-only, OpenMP threaded Q++ library. \n",
    "\n",
    "\n",
    "Available TargetsÂ¶\n",
    "\n",
    "        qpp-cpu: The default multithreaded CPU backend.\n",
    "        nvidia: GPU based backend which accelerates quantum circuit simulation on NVIDIA GPUs.\n",
    "        nvidia-mqpu: Enables users to program workflows utilizing multiple quantum processors enabled today by GPU emulation.\n",
    "        nvidia-mgpu: Allows for scaling circuit simulation beyond what is feasible with any QPU today.\n",
    "        density-matrix-gpu: Noisy simulations via density matrix calculations. CPU version if also availabel.\n",
    "        tensornet: GPU accelerated TN backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"images/targets.png\" alt=\"Image Title\" width=\"600\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target nvidia-mgpu\n",
      "\tsimulator=nvidia_mgpu\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target quantinuum\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target photonics\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target density-matrix-cpu\n",
      "\tsimulator=dm\n",
      "\tplatform=default\n",
      "\tdescription=The Density Matrix CPU Target provides a simulated QPU via OpenMP-enabled, CPU-only density matrix emulation.\n",
      "\n",
      "Target iqm\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia-mqpu-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU FP64 Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP64.\n",
      "\n",
      "Target tensornet\n",
      "\tsimulator=tensornet\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target orca\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target qpp-cpu\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=QPP-based CPU-only backend target\n",
      "\n",
      "Target remote-mqpu\n",
      "\tsimulator=qpp\n",
      "\tplatform=mqpu\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia-mqpu\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=mqpu\n",
      "\tdescription=The NVIDIA MQPU Target provides a simulated QPU for every available CUDA GPU on the underlying system. Each QPU is simulated via cuStateVec FP32. This target enables asynchronous parallel execution of quantum kernel tasks.\n",
      "\n",
      "Target tensornet-mps\n",
      "\tsimulator=tensornet_mps\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target nvidia\n",
      "\tsimulator=custatevec_fp32\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA Target provides a simulated QPU via single-GPU cuStateVec integration on FP32 types.\n",
      "\n",
      "Target nvidia-fp64\n",
      "\tsimulator=custatevec_fp64\n",
      "\tplatform=default\n",
      "\tdescription=The NVIDIA FP64 Target provides a simulated QPU via single-GPU cuStateVec integration on FP64 types.\n",
      "\n",
      "Target ionq\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n",
      "Target oqc\n",
      "\tsimulator=qpp\n",
      "\tplatform=default\n",
      "\tdescription=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print all the availble targets for your system\n",
    "import cudaq\n",
    "\n",
    "targets = cudaq.get_targets()\n",
    "\n",
    "for target in targets:\n",
    "    print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Some  ways to scale your application:\n",
    "  \n",
    "    1. Increasing the number of qubits (weak scaling)\n",
    "    \n",
    "            - mgpu backend\n",
    "    \n",
    "    2. Distributing the circuit execution (strong scaling)\n",
    "            2.1 asynchronous sampling\n",
    "            2.2 Hamiltonian batching\n",
    "            2.3 Parameter batching\n",
    "\n",
    "            - mqpu backend\n",
    "            - Each gpu acts as a virtual qpu\n",
    "\n",
    "         As a rule of thumb, we can parallelize over any of the input parameters to `cudaq.sample()` or `cudaq.observe()` - kernel, hamiltonian, kernel parameters, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple NVIDIA GPUs for the mgpu backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - The increase in qubit count leads to an exponential increase in the size of the statevector.\n",
    "    \n",
    "    - The nvidia-mgpu target allows for scaling the qubit count by pooling memory from GPUs across multiple nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous sampling via mqpu backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QPUs: 2\n",
      "{ 00:493 11:507 }\n",
      "\n",
      "{ 00:463 11:537 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Please run this code snippet in a Python script only using\n",
    "# mpirun -np N python <filename>\n",
    "# N is the number of gpus you have available \n",
    "\n",
    "import cudaq \n",
    "\n",
    "# set the target here\n",
    "# alternatively this target could also be set at runtime\n",
    "cudaq.set_target(\"nvidia-mqpu\")\n",
    "target = cudaq.get_target()\n",
    "num_qpus = target.num_qpus()\n",
    "print(\"Number of QPUs:\", num_qpus)\n",
    "\n",
    "# Construct a quantum circuit\n",
    "kernel = cudaq.make_kernel()\n",
    "qubits = kernel.qalloc(2)\n",
    "kernel.h(qubits[0])\n",
    "kernel.cx(qubits[0], qubits[1])\n",
    "kernel.mz(qubits)\n",
    "\n",
    "# Sample the circuits asynchronously\n",
    "futures = []\n",
    "for i in range(num_qpus):\n",
    "  futures.append(cudaq.sample_async(kernel, qpu_id=i))\n",
    "  \n",
    "# You can do some other processing while you wait\n",
    "# for your asynchronous results \n",
    "  \n",
    "# Extract the results\n",
    "for count in futures:\n",
    "    print(count.get())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      Asynchronous expectation value computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run this code snippet in a Python script using\n",
    "# mpirun -np N python <filename>\n",
    "# N is the number of gpus you have available \n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "kernel = cudaq.make_kernel()\n",
    "qubit = kernel.qalloc()\n",
    "kernel.x(qubit)\n",
    "\n",
    "# Measuring in the Z-basis.\n",
    "hamiltonian = spin.z(0)\n",
    "\n",
    "# Call `cudaq.observe()` at the specified number of shots.\n",
    "future = cudaq.observe_async(kernel=kernel,\n",
    "                            spin_operator=hamiltonian,\n",
    "                            qpu_id=0,\n",
    "                            shots_count=2000)\n",
    "observe_result = future.get()\n",
    "got_expectation = observe_result.expectation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Hamiltonian term distribution over multiple QPUs\n",
    "<div style=\"display:flex;justify-content:center;\">\n",
    "    <img src=\"images/hsplit.png\" alt=\"Image Title\" width=\"500\">\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
